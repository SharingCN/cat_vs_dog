{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习纳米学位毕业项目 -- 猫狗大战\n",
    "\n",
    "苗沛\n",
    "\n",
    "2018.08.15\n",
    "\n",
    "**实验环境**\n",
    "\n",
    "- MacBook 10.13.6\n",
    "- python 3.5.4\n",
    "- numpy 1.13.0\n",
    "- tensorflow 1.3.0\n",
    "- Keras 1.2.2\n",
    "- h5py 2.7.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "\n",
    "从 [Dogs vs. Cats Redux: Kernels Edition](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data) 下载训练数据到`image目录` 并解压到当前目录。\n",
    "\n",
    "数据集的文件名是以type.num.jpg方式命名的，比如cat.0.jpg。使用 Keras 的 ImageDataGenerator 需要将不同种类的图片分在不同的文件夹中。对数据集进行预处理参考的是[杨培文的Blog](http://www.zhiding.cn/techwalker/documents/J9UpWRDfVYHE5WsOEHbyx4eM8fBcpHYEW_b72QCUihQ)创建符号链接(symbol link)的方法，这样的好处是不用复制一遍图片，占用不必要的空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "os.chdir(\"{}/image\".format(os.getcwd())) \n",
    "\n",
    "train_filenames = os.listdir('train')\n",
    "train_cat = filter(lambda x:x[:3] == 'cat', train_filenames)\n",
    "train_dog = filter(lambda x:x[:3] == 'dog', train_filenames)\n",
    "\n",
    "def rmrf_mkdir(dirname):\n",
    "    if os.path.exists(dirname):\n",
    "        shutil.rmtree(dirname)\n",
    "    os.mkdir(dirname)\n",
    "\n",
    "rmrf_mkdir('img_train')\n",
    "os.mkdir('img_train/cat')\n",
    "os.mkdir('img_train/dog')\n",
    "\n",
    "rmrf_mkdir('img_test')\n",
    "os.symlink('../test/', 'img_test/test')\n",
    "\n",
    "for filename in train_cat:\n",
    "    os.symlink('../../train/'+filename, 'img_train/cat/'+filename)\n",
    "\n",
    "for filename in train_dog:\n",
    "    os.symlink('../../train/'+filename, 'img_train/dog/'+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像文件分类后的路径如下：\n",
    "\n",
    "``` python \n",
    "├── test [12500 images]\n",
    "├── test2\n",
    "│   └── test -> ../test/\n",
    "├── train [25000 images]\n",
    "└── train2\n",
    "    ├── cat [12500 images]\n",
    "    └── dog [12500 images]\n",
    "\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFpIkqRqDhSRJqsZgIUmSqjFYSJKkav4/Q+meB3M8j48AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7cf1820da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "x = ['train_cat', 'train_dog', 'test']\n",
    "y = [len(os.listdir('img_train/cat')), len(os.listdir('img_train/dog')), len(os.listdir('test'))]\n",
    "ax = sns.barplot(x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image数据集中，猫的数量：12500，狗的数量：12500，测试集图片数量：12500'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_count = \"\"\"image数据集中，猫的数量：{}，狗的数量：{}，测试集图片数量：{}\"\"\".format(len(os.listdir('img_train/cat')), len(os.listdir('img_train/dog')),len(os.listdir('test')))\n",
    "s_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导出特征向量\n",
    "\n",
    "对于这个题目来说，使用预训练的网络是最好不过的了，经过前期的测试，我们测试了 ResNet50 等不同的网络，但是排名都不高，现在看来只有一两百名的样子，所以我们需要提高我们的模型表现。那么一种有效的方法是综合各个不同的模型，从而得到不错的效果，兼听则明。如果是直接在一个巨大的网络后面加我们的全连接，那么训练10代就需要跑十次巨大的网络，而且我们的卷积层都是不可训练的，那么这个计算就是浪费的。所以我们可以将多个不同的网络输出的特征向量先保存下来，以便后续的训练，这样做的好处是我们一旦保存了特征向量，即使是在普通笔记本上也能轻松训练。\n",
    "\n",
    "经典的CNN输入图像的尺寸，是224×224、227×227、256×256和299×299，但也可以是其他尺寸。\n",
    "\n",
    "VGG16，VGG19和ResNet均接受224×224输入图像，而Inception V3和Xception需要299×299像素输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "import h5py\n",
    "\n",
    "def write_gap(MODEL, image_size, lambda_func=None):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)\n",
    "    \n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "    \n",
    "    gen = ImageDataGenerator()\n",
    "    train_generator = gen.flow_from_directory(\"img_train\", image_size, shuffle=False, \n",
    "                                              batch_size=16)\n",
    "    test_generator = gen.flow_from_directory(\"img_test\", image_size, shuffle=False, \n",
    "                                             batch_size=16, class_mode=None)\n",
    "\n",
    "    train = model.predict_generator(train_generator, train_generator.nb_sample)\n",
    "    test = model.predict_generator(test_generator, test_generator.nb_sample)\n",
    "\n",
    "    with h5py.File(\"gap_%s.h5\"%MODEL.__name__) as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#write_gap(ResNet50, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write_gap(InceptionV3, (299, 299), inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write_gap(Xception, (299, 299), xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入特征向量\n",
    "\n",
    "经过上面的代码以后，我们获得了三个特征向量文件，分别是：\n",
    "\n",
    "- gap_ResNet50.h5\n",
    "- gap_InceptionV3.h5\n",
    "- gap_Xception.h5\n",
    "\n",
    "这里需要载入这些特征向量，并且将它们合成一条特征向量，然后记得把 X 和 y 打乱，不然之后设置validation_split的时候会出问题。这里设置了 numpy 的随机数种子为2018。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(2018)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "for filename in [\"gap_ResNet50.h5\", \"gap_Xception.h5\", \"gap_InceptionV3.h5\"]:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        X_test.append(np.array(h['test']))\n",
    "        y_train = np.array(h['label'])\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型\n",
    "\n",
    "模型的构建很简单，直接 dropout 然后分类就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/miaopei/anaconda2/envs/cat_vs_dog/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1108: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "x = input_tensor\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, x)\n",
    "\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对模型进行可视化：\n",
    "\n",
    "进入model_graphviz目录执行make，生成model.png\n",
    "\n",
    "<img src=\"source/model.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"source/nnarch1-1.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "\n",
    "模型构件好了以后，我们就可以进行训练了，这里我们设置验证集大小为 20% ，也就是说训练集是20000张图，验证集是5000张图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"221pt\" viewBox=\"0.00 0.00 277.00 221.00\" width=\"277pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-217 273,-217 273,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140174120493184 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140174120493184</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 269,-212.5 269,-166.5 0,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-185.8\">input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"125,-166.5 125,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"125,-189.5 180,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"180,-166.5 180,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"224.5\" y=\"-197.3\">(None, 6144)</text>\n",
       "<polyline fill=\"none\" points=\"180,-189.5 269,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"224.5\" y=\"-174.3\">(None, 6144)</text>\n",
       "</g>\n",
       "<!-- 140174120493968 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140174120493968</title>\n",
       "<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 269,-129.5 269,-83.5 0,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-102.8\">dropout_1: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"125,-83.5 125,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"125,-106.5 180,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"180,-83.5 180,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"224.5\" y=\"-114.3\">(None, 6144)</text>\n",
       "<polyline fill=\"none\" points=\"180,-106.5 269,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"224.5\" y=\"-91.3\">(None, 6144)</text>\n",
       "</g>\n",
       "<!-- 140174120493184&#45;&gt;140174120493968 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140174120493184-&gt;140174120493968</title>\n",
       "<path d=\"M134.5,-166.3799C134.5,-158.1745 134.5,-148.7679 134.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"138.0001,-139.784 134.5,-129.784 131.0001,-139.784 138.0001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140174120494360 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140174120494360</title>\n",
       "<polygon fill=\"none\" points=\"11.5,-.5 11.5,-46.5 257.5,-46.5 257.5,-.5 11.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-19.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"113.5,-.5 113.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"113.5,-23.5 168.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"168.5,-.5 168.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213\" y=\"-31.3\">(None, 6144)</text>\n",
       "<polyline fill=\"none\" points=\"168.5,-23.5 257.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213\" y=\"-8.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 140174120493968&#45;&gt;140174120494360 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140174120493968-&gt;140174120494360</title>\n",
       "<path d=\"M134.5,-83.3799C134.5,-75.1745 134.5,-65.7679 134.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"138.0001,-56.784 134.5,-46.784 131.0001,-56.784 138.0001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hist = model.fit(X_train, y_train, batch_size=128, nb_epoch=8, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/8\n",
      "20000/20000 [==============================] - 1s - loss: 0.1099 - acc: 0.9651 - val_loss: 0.0309 - val_acc: 0.9912\n",
      "Epoch 2/8\n",
      "20000/20000 [==============================] - 1s - loss: 0.0286 - acc: 0.9919 - val_loss: 0.0224 - val_acc: 0.9922\n",
      "Epoch 3/8\n",
      "20000/20000 [==============================] - 1s - loss: 0.0237 - acc: 0.9922 - val_loss: 0.0197 - val_acc: 0.9934\n",
      "Epoch 4/8\n",
      "20000/20000 [==============================] - 1s - loss: 0.0202 - acc: 0.9938 - val_loss: 0.0183 - val_acc: 0.9940\n",
      "Epoch 5/8\n",
      "20000/20000 [==============================] - 1s - loss: 0.0190 - acc: 0.9934 - val_loss: 0.0175 - val_acc: 0.9938\n",
      "Epoch 6/8\n",
      "20000/20000 [==============================] - 1s - loss: 0.0168 - acc: 0.9942 - val_loss: 0.0173 - val_acc: 0.9948\n",
      "Epoch 7/8\n",
      "20000/20000 [==============================] - 1s - loss: 0.0155 - acc: 0.9950 - val_loss: 0.0173 - val_acc: 0.9942\n",
      "Epoch 8/8\n",
      "20000/20000 [==============================] - 1s - loss: 0.0152 - acc: 0.9951 - val_loss: 0.0170 - val_acc: 0.9944\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import *\n",
    "\n",
    "model_history = model.fit(X_train, \n",
    "                    y_train,\n",
    "                    batch_size=128,\n",
    "                    nb_epoch=8,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks = [TensorBoard(log_dir='./Graph')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorboard --logdir='你存event的目录'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['val_loss'])\n",
    "#plt.xlabel('time')\n",
    "#plt.ylabel('val_loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['val_acc'])\n",
    "#plt.xlabel('times')\n",
    "#plt.ylabel('val_acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# 画图\n",
    "def plot_training(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    epochs = range(len(acc))\n",
    "    plt.plot(epochs, acc, 'r.')\n",
    "    plt.plot(epochs, val_acc, 'r')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.figure()\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']   \n",
    "    plt.plot(epochs, loss, 'r.')\n",
    "    plt.plot(epochs, val_loss, 'r-')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.show()\n",
    "\n",
    "# 训练的acc_loss图\n",
    "plot_training(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测测试集\n",
    "\n",
    "模型训练好以后，我们就可以对测试集进行预测，然后提交到 kaggle 上看看最终成绩了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "image_size = (224, 224)\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(\"img_test\", image_size, shuffle=False, \n",
    "                                         batch_size=16, class_mode=None)\n",
    "\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('pred.csv', index=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测这里我们用到了一个小技巧，我们将每个预测值限制到了 [0.005, 0.995] 个区间内，这个原因很简单，kaggle 官方的评估标准是 LogLoss，对于预测正确的样本，0.995 和 1 相差无几，但是对于预测错误的样本，0 和 0.005 的差距非常大，是 15 和 2 的差别。参考 LogLoss 如何处理无穷大问题，下面的表达式就是二分类问题的 LogLoss 定义。\n",
    "\n",
    "$$\\textrm{LogLoss} = - \\frac{1}{n} \\sum_{i=1}^n \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)\\right]$$\n",
    "\n",
    "还有一个值得一提的地方就是测试集的文件名不是按 1, 2, 3 这样排的，而是按下面的顺序排列的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%ls test | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此我们需要对每个文件名进行处理，然后赋值到 df 里，最后导出为 csv 文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "data = pd.read_csv(\"pred.csv\")\n",
    "display(data.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator()\n",
    "train_generator = gen.flow_from_directory(\"img_train\", (224, 224), shuffle=False, batch_size=16)\n",
    "\n",
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip([x.name for x in model.layers], range(len(model.layers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 模型概括\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 模型可视化\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True) # plot my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model2 = Model(model.input, [model.layers[2].output, model.output])\n",
    "#model2 = Model(input=model.input, output=model.get_layer(dense_1).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.figure(figsize=(12, 14))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    img = cv2.imread('test/%d.jpg' % random.randint(1, 12500))\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    x = img.copy()\n",
    "    x.astype(np.float32)\n",
    "    #print(np.expand_dims(x, axis=0))\n",
    "    out, prediction = model2.predict(np.expand_dims(x, axis=0))\n",
    "    #out, prediction = model2.predict(x)\n",
    "\n",
    "    prediction = prediction[0]\n",
    "    out = out[0]\n",
    "\n",
    "    if prediction < 0.5:\n",
    "        plt.title('cat %.2f%%' % (100 - prediction*100))\n",
    "    else:\n",
    "        plt.title('dog %.2f%%' % (prediction*100))\n",
    "\n",
    "    cam = (prediction - 0.5) * np.matmul(out, weights)\n",
    "    cam -= cam.min()\n",
    "    cam /= cam.max()\n",
    "    cam -= 0.2\n",
    "    cam /= 0.8\n",
    "\n",
    "    cam = cv2.resize(cam, (224, 224))\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET)\n",
    "    heatmap[np.where(cam <= 0.2)] = 0\n",
    "\n",
    "    out = cv2.addWeighted(img, 0.8, heatmap, 0.4, 0)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.imshow(out[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
